---
title: "Repository 6"
author: "David Greussing"
date: "31 10 2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)


remotes::install_github("braverock/factorAnalytics",  build_vignettes = TRUE, force = TRUE)
pacman::p_load(tidyverse,tidyquant,FFdownload,FactorAnalytics,PerformanceAnalytics)
pacman::p_load(tidyverse,tidyquant,FFdownload,PortfolioAnalytics,nloptr)
pacman::p_load(tidyverse,tidyquant,PortfolioAnalytics,nloptr,tsibble,matrixcalc,Matrix,timetk,xts)
```

```{r}
## Important Function

#       fitTsfm
#   
#     fitTsfm(asset.names, factor.names, data, fit.method, variable.selection, ...):
#     
#     Fits a time series (a.k.a. macroeconomic) factor model for one or more asset returns or excess
#     returns using time series regression. Least squares (LS), discounted least squares (DLS) and
#     robust regression fitting are possible. Variable selection methods include "stepwise", "subsets" and "lars". An object of class "tsfm" containing the
#     fitted objects, estimated coefficients, R-squared and residual volatility is returned.

```


**Please** remember to put your assignment solutions in `rmd` format using **many** chunks and putting readable text in between, similar to my examples given in Research Methods and Assignment 1!

For all exercises: Please use the Assignment-Forum to post your questions, I will try my best to help you along! If you follow the vignettes from `factorAnalytics`, wherever it says `z.score=T`, please exchange it for either `z.score='crossSection'` or `z.score='timeSeries'` depending on the task at hand.

## Exercise 1: Estimating the CAPM (from A05)

In this exercise we want to estimate the CAPM. Please read carefully through the two documents provided (right hand side: files). Then we start to collect the necessary data:
  
a) From Datastream get the last 10 years of data from the 100 stocks of the S&P100 using the list `LS&P100I` (S&P 100): total return index (RI) and market cap (MV)
b) Further import the Fama-French-Factors from Kenneth Frenchs homepage (monthly, e.g. using `FFdownload`). From both datasets we select data for the last (available) 60 months, calculate returns (simple percentage) for the US-Stocks and eliminate those stocks that have NAs for this period.
c) Now subtract the risk-free rate from all the stocks. Then estimate each stocks beta with the market: Regress all stock excess returns on the market excess return and save all betas (optimally use `mutate` and `map` in combination with `lm`). Estimate the mean-return for each stock and plot the return/beta-combinations. Create the security market line and include it in the plot! What do you find?
d) In a next step (following both documents), we sort the stocks according to their beta and build ten value-weighted portfolios (with more or less the same number of stocks). Repeat a) for the ten portfolios. What do you observe?
e) In the third step you follow page 6-8 of the second document and estimate the second-pass regression with the market and then market & idiosyncratic risk. What do you observe? Present all your results in a similar fashion as in the document.

## Exercise 2: Calculating and checking the CAPM cont. (from A05)

As we have seen: the CAPM for small portfolios does not work very well, and so we start using portfolios that get rid of the idiosyncratic risk!
Go to Kenneth French's Homepage  again and download the following datasets: "Portfolios Formed on Market Beta" (where we will use 10 monthly value weighted portfolios formed on beta) and "25 Portfolios Formed on Size and Market Beta" (same thing) as well as the market factor and rf (as before). Now we are going to check the CAPM like famous researchers have done it!
We can use returns as they are in the files (simple returns)!

a)	Subtract the risk-free rate from the first set of 10 portfolios (only sorted on beta) (Lo 10,., Hi 10) and estimate each stocks beta with the market. Estimate the mean-return for each stock and plot the return/beta-combinations. Create the security market line and include it in the plot! What do you find? (You can split the file in 2-3 different time blocks and see if something changes). * Now we are done with the first-pass regression.*
b)	In the second-pass regression we now regress the average stock returns on the betas estimated before. What do you find in the coefficients and does this contradict the CAPM? Try different time periods again and see what you find. (all of the interpretations are in BKM pp.416f). 
c)	Now do the extended second pass regression (regress on betas and residual-sds that you can extract from the regression) and see what you find for different periods. Interpret according to concept check 13.2. One of the (many) problems of the CAPM can be the correlation between residual variances and betas. Calculate and interpret.
d)	Try again with 25 portfolios sorted on size and beta. What do you find? Is that interesting? 


**The purpose of the further assignments is less programming-related (you can copy most of the code), but to receive a positive grade I want you to dig into the referenced literature and be able to explain _everything_ that you do very detailed in the text and your presentation (what do you do, what is the result and how do you intepret the result). After doing this - given the data - you should be perfectly able to estimate/interpret any type of factor model.**
  
## Exercise 3: Statistical Factor Models

Follow the file [sfmVignette.pdf](https://github.com/braverock/FactorAnalytics/blob/master/vignettes/sfmVignette.pdf) and interpret your results.

## Exercise 4: Timeseries Factor Models

Follow the file [tsfmVignette.pdf](https://github.com/braverock/FactorAnalytics/blob/master/vignettes/tsfmVignette.pdf) and interpret your results.

### Theorie
In a time series or macroeconomic factor model, observable economic time series such as industrial production growth rate, interest rates, market returns and inflation are used as common factors that contribute to asset returns. 
- For example, the famous *single index model by Sharpe* (1964) uses the market excess return as the *common factor* (captures economy-wide or market risk) for all assets and the *unexplained returns in the error term* represents the *non-market firm specific risk*. 
- On the other hand, *Chen et al. (1986) uses a multi-factor model* to find that surprise inflation, the spread between long and short-term interest rates and between high and low grade bonds are *significantly priced*, while the market portfolio, aggregate consumption risk and oil price risk are *not priced separately*.

```{r}

install.packages("factorAnalytics", repos="http://R-Forge.R-project.org")

options(digits=3)

```


```{r}
# The following examples primarily use the managers dataset from the PerformanceAnalytics package. 
# It’s an "xts" data object with:
#                                 - 132 observations of monthly returns
#                                 - on 10 variables:
#                                     - six hypothetical asset managers, 
#                                     - 1x dhec returns (Long-Short Equity hedge fund index)
#                                     - 1x sp500 returns
#                                     - US treasury bonds 10 years (will serve as explanatory factors)
#                                     - US treasury bills 3 months (can be considered as the risk free rate)
#                                 - there are some "not available" observations (start day!)

data(managers)

# We want to see the managers names
colnames(managers)

# and we want to see from when to when the data is available 
range(index(managers))

```

```{r}

# the Ham1-Ham6 are the asset returns we want to explain --> y in our model
asset.names <- colnames(managers[,1:6]) 

# the edhec, sp500 & US Treasury they are the explanatory ones --> x in our model
factor.names <- colnames(managers[,7:9]) 

# Typically, factor models are fit using excess returns. If the asset and factor returns are not in excess return form, "rf.name" can be specified to convert returns into excess returns. 
rf.name <- "US.3m.TR"

# Similarly, market returns can be specified via "mkt.name" to add market-timing factors to the factor model.
mkt.name <- "SP500.TR" 

```

### Let’s take a look at the arguments for *fitTsfm*.

The default model fitting method is *LS regression* and the default variable selection method
is "none" (that is, all factors are included in the model). 
The different model fitting options are: 
- least squares (LS), 
- discounted least squares (DLS) and
- robust regression fitting (Robust)


And variableselection options are:
- "stepwise", 
- "subsets" and 
- "lars"

The default for rf.name and mkt.name are NULL. If rf.name is not specified by the user,
perhaps because the data is already in excess return form, then no risk-free rate adjustment is
made. Similarly, if mkt.name is not specified, market-timing factors are not added to the model.
All other optional control parameters passed through the ellipsis are processed and assimilated
internally by fitTsfm.control.

```{r}

# The series have unequal histories in this sample and “fitTsfm“ removes asset-wise incomplete cases (asset’s return data combined with respective factors’ return data) before fitting a factor model.
args(fitTsfm)

```

```{r}

# Single Index Model using SP500 
fit.singleIndex <- fitTsfm(asset.names=asset.names, 
                           factor.names="SP500.TR",   #specfic factor!
                           rf.name="US.3m.TR", 
                           data=managers)

# Interpretation:
# if the market return rises 1%, then the return of Ham1 rises 0,39%
# R-squared: 1 would be 100% - linear function matches perfectly with the data --> here we have low R-squared

```

```{r}

class(fit.singleIndex)

```

```{r}

names(fit.singleIndex)

```

Overview of the single factor linear fits for the assets. 
```{r}

fit.singleIndex
# Interpretation:
# How good does the single index model fits to the data?
# Ham1 equals a linear regression the most --> fits the best --> R-squared is the highest
# Ham5 does not really fit to this mode --> alfa and R-squared values

```

```{r}

plot(fit.singleIndex, which=12, f.sub=1)

```

### Henriksson-Merton's - market timing models
Market timing accounts for the price movement of the general stock market relative to fixed income securities.
This includes the down.market factor --> max(0, Rf-Rm)
To test market timing ability, this factor can be added to the single index model as shown below. The coefficient of this down-market factor can be
interpreted as the number of "free" put options on the market provided by the manager’s markettimings kills. That is, a negative value for the regression estimate would imply a negative value for market timing ability of the manager.

```{r}

# Henriksson-Merton's market timing model
fit.mktTiming <- fitTsfmMT(asset.names=asset.names, 
                           mkt.name="SP500.TR", # specify which of the columns in data corresponds to the market returns using argument mkt.name.
                           rf.name="US.3m.TR", 
                           data=managers)

t(fit.mktTiming$beta)

# Interpretation:
# when the value of down.market is negative, the ability of market timing of a manager is low --> not even there
# so the manager 2 has the best ability of market timing and after that manager 6 --> they have the hightes intercept (which return they will make when the market makes no return)

```


```{r}

fit.mktTiming$r2
# Interpretation:
# R^2 -> how good the data fits to the model

```

```{r}

fit.mktTiming$resid.sd
# Interpretation:
# volatility: how much it jumps around relative to its relationship to an index(sp500)
# risk: the higher the worse

###fit methods
#ls = least squares
#dls = discounted least squares (weightes least squares)
#robust = is good for data with outliers

```

Fits Model:

The different model fitting options are: 
- (ordinary) least squares (ols / LS) --> Default mode!
- discounted least squares (DLS) and
- robust regression fitting (Robust)

### Ordinary least squares ("ols")

```{r}
#  The next example performs LS regression using all 3 available factors in the dataset.
fit.ols <- fitTsfm(asset.names=asset.names, 
                   factor.names=factor.names, # all 3 available factors: the edhec, sp500 & US.10Y.TR/US Treasury
                   rf.name="US.3m.TR", 
                   data=managers) 


fit.ols$beta
# Interpretation:
# now we consider all factors (explanatory factors)

# Sensitivity: 
# when the return of edhec rises 1% --> Ham2 rises 0,1547%
# when sp500 return rises 1%, Ham2 decreases by 0,195%
# when US.10Y.TR return rises 1%, Ham2 decreases by 0,0504%
```

```{r}

fit.ols$r2
# Interpretation:
# how good does the data fit to the model
# Ham3 fits the best with 66%

```

```{r}

fit.ols$resid.sd
# Interpretation:
# Volatility
# How much they jump around --> most Ham4 0.0427

```


### Discounted least squares ("ols")
DLS is least squares regression using exponentially discounted weights and accounts for time variation in coefficients. Robust regression is resistant to outliers.
```{r}
```

### Other options robust regression ("Robust"). 
```{r}

fit.robust <- fitTsfm(asset.names=asset.names, 
                      factor.names=factor.names, 
                      rf.name="US.3m.TR", 
                      data=managers, 
                      fit.method="Robust") # Method "Robust"!
fit.robust$beta
# Interpretation:

```

```{r}

fit.robust$r2
# Interpretation:
# R-squared is now lower for each
# maybe they all had outliers

```


```{r}

fit.robust$resid.sd
# Interpretation:

```

```{r}

par(mfrow=c(2,1)) 
plot(fit.ols, plot.single=TRUE, which=1, asset.name="HAM3") 
mtext("LS", side=3) 
plot(fit.robust, plot.single=TRUE, which=1, asset.name="HAM3") mtext("Robust", side=3)

# Interpretation:
# volatility is smaller when using the robust fitting method
### variable selection

# lars is a good variable to add
# least angle regression
# it is good when you are afraid of overfitting (that you adjust your model too much)
# when you have high-dimensional data (lots of explanatory factors)

```

```{r}

par(mfrow=c(1,2)) 
plot(fit.ols, which=5, xlim=c(0,0.045), sub="LS") 
plot(fit.robust, which=5, xlim=c(0,0.045), sub="Robust")

```

Though the R-squared values improved by adding more factors in fit.ols (compared to the single index model)

### Variable Selection
One might prefer to employ variable selection methods such as "stepwise", "subsets" or "lars" to avoid over-fitting. The method can be selected via the variable.selection argument. The default "none", uses all the factors and performs no variable selection.
- Specifying *"stepwise"* selects traditional stepwise LS or robust regression using step or step.lmRob respectively. Starting from the given initial set of factors, factors are added (or subtracted) only if the regression fit improves.
- Specifying *"subsets"* enables subsets selection using regsubsets. The best performing subset of any given size or within a range of subset sizes is chosen. Different methods such as exhaustive search (default), forward or backward stepwise, or sequential replacement can be employed.
- Finally, *"lars"* corresponds to least angle regression using lars with variants "lasso" (default), "lar", "forward.stagewise" or "stepwise".

#### LARS = least angle regression 

```{r}

fit.lars <- fitTsfm(asset.names=asset.names, 
                    factor.names=factor.names, 
                    data=managers, 
                    rf.name="US.3m.TR", 
                    variable.selection="lars") 

fit.lars
# Interpretation:
# Subset --> the best performing subset within a range of subset sizes is chosen

```

```{r}

fit.sub <- fitTsfm(asset.names=asset.names, 
                   factor.names=factor.names, 
                   data=managers, 
                   rf.name="US.3m.TR", 
                   variable.selection="subsets", 
                   nvmin=2, nvmax=2) 
# Here, the best subset of size 2 for each asset is chosen by specifying nvmin = nvmax = 2. Note that when nvmin < nvmax, the best subset is chosen from a range of subset sizes [nvmin, nvmax]. Default is nvmin = 1.

# Interpretation:
# we see all together
# intercepts = alpha
# where we see the indices --> betas

```

```{r}

plot(fit.sub, which=2, f.sub=1:3)

```

```{r}

plot(fit.lars, which=2, f.sub=1:3)

```

Comparing the *coefficients* and *R-squared values* from the two models, we find that the method that uses *more factors* for an asset have higher R-squared values as expected. However, when both "lars" and "subsets" chose the same number of factors, "lars" fits have a slightly higher R-squared values.


###  S3 generic methods
Many useful generic accessor functions are available for "tsfm" fit objects:
- coef() returns a matrix of estimated model coefficients including the intercept. 
- fitted() returns an xts data object of the component of asset returns explained by the factor model. 
- residuals() returns an xts data object with the component of asset returns not explained by the factor model. 
- predict() uses the fitted factor model to estimate asset returns given a set of new or simulated factor return data.
- summary() prints standard errors and t-statistics for all estimated coefficients in addition to R-squared values and residual volatilities. 

Argument se.type, one of "Default", "HC" or "HAC", allows for heteroskedasticity and auto-correlation consistent estimates and standard errors whenever possible. A "summary.tsfm" object is returned which contains a list of summary objects returned by "lm", "lm.Rob" or "lars" for each asset fit.

```{r}

methods(class="tsfm")

```

All estimated coefficients from the LS fit using all 3 factors
```{r}

coef(fit.ols)

```

Compare returns data with fitted and residual values for HAM1 from fit.lars

```{r}

HAM1.ts <- merge(fit.lars$data[,1], 
                 fitted(fit.lars)[,1], 
                 residuals(fit.lars)[,1]) 

colnames(HAM1.ts) <- c("HAM1.return","HAM1.fitted","HAM1.residual") 

tail(HAM1.ts)

# Interpretation:
# fitted --> the returns which can be explained through the model
# residual --> the returns which cannot be explained through the model
```

### Summary for fit.sub computing HAC standard erros

```{r}

summary(fit.sub, se.type="HAC")

```

## Exercise 5: Fundamental Factor Models

Follow the file [ffmVignette.pdf](https://github.com/braverock/FactorAnalytics/blob/master/vignettes/ffmVignette.pdf) and interpret your results.

### Theorie
The general mathematical form of equity fundamental factor model (FFM) implemented in factorAnalytics is
rt = αt· 1 + Bt−1ft + εt, t = 1, 2, · · · , T (1)

where:
- equity returns vector rt and the vectors 1 and 
- εt are N ×1 vectors, 
- Bt−1 is an N ×K exposures (risk factors) matrix, and 
- ft is a K × 1 vector of random factor returns. 
- It is assumed that the εt hav zero mean with diagonal covariance matrix Dt = diag(σ2 t,1, σ2 t,2, · · · , σ2 t,N), and are uncorrelated
with the ft


```{r}

# factorAnalytics
# The following U.S. stock returns and data sets are included in factorAnalytics for now:
#
# 1) factorDataSetDjia: 
#                       - Monthly returns of 30 stocks in the DJIA from January 2000 to March 2013 = Dow Jones Industrial Average 
#                       - with 5 corresponding style factors:
#                           - MKTCAP  (Market Capitalization)
#                           - ENTVAL  (Entitled Value)
#                           - P2B     ()
#                           - EV2S    ()
#                           - SIZE    ()
#                       - and a sector factor with 9 sectors:
#                           - ENERGY  (Energy), 
#                           - COSTAP  (Consumer Staples), 
#                           - INDUST  (Industry), 
#                           - MATRLS  (Materials), 
#                           - FINS    (Financials), 
#                           - INFOTK  (Information Technology), 
#                           - HEALTH  (Healthcare)
#                           - CODISC  (Consumer Discretionary), 
#                           - TELCOM  (Telecommunications)] 
# 
#
# 2) factorDataSetDjia5Yrs: 
#                       - A five-year segment of factorDataSetDjia from January 2008 to December 2012.
#
#
# 3) wtsDjiaGmvLo: 
#                       - Weight vector of dimension 30 containing the weights of a long-only 
#                         global minimum variance (GMV) portfolio for the 30 stocks in the factorDataSetDjia5Yrs data set.
#                       - The weight vector was obtained using PortfolioAnaltyics with the usual sample covariance matrix 
#                         based on the 5 years of returns in factorDataSetDjia5Yrs.


data("factorDataSetDjia5Yrs") 

dataDjia5Yr = factorDataSetDjia5Yrs 

head(dataDjia5Yr,5) 
``` 
 
 
### 1. Fitting a Fundamental Factor Model - FFM 
A FFM is generally fit by a two-step method:
1) using least squares or robust regression methods in the first step, 
2) and using weighted least squares or weighted robust regression in the second step where the weights are computed in the first step.


# The Fundamental-Factor-Model-Function: fitFfm

fitDjia5Yr = fitFfm(dataDjia5Yr, addIntercept = T, 
                    asset.var = "TICKER",                                 # asset.var = name of variable for asset names 
                    ret.var = "RETURN",                                   # ret.var = name of variable for asset returns 
                    date.var = "DATE",                                    # date.var = name of variable containing the dates 
                    exposure.vars = c("SECTOR","SIZE", "P2B", "EV2S"),    # exposrue.var = variables containing the fundamental factor exposures 
                    z.score = "crossSection")                             # z.score has to be one of "none", "crossSection", or "timeSeries" 

names(fitDjia5Yr) 
``` 
#### 1.1. Model Fit R-Squared Values
One of the most basic model fit statistics is the R-squared, and you can assess the goodness of your FFM fits by using the function ffmRsq to make a plot of the time series of R-squared values for each of the 60 fits over the five-year window. This function computes and plots the time series of ordinary R-squared by default, but it can do that for the adjusted R-squared, or both.

```{r} 

# Fit R-Squared Values

fmRsq(fitDjia5Yr,
      rsq = T,              # logical; if TRUE, Factor Model R-squared values are computed for the portfolio. Default is TRUE.
      rsqAdj = T,           # logical; if TRUE, Adjusted R-squared values are computed for the portfolio. Default is FALSE.
      plt.type = 2,         # 1 indicates barplot, 2 indicates time series xy plot. Default is 2.
      isPrint = F, 
      lwd = 0.7, 
      stripText.cex = 0.8, 
      axis.cex = 0.8) 
 
# Interpretation:
# 1) Upper Plot: Mean R-Squared across periods = 0.78 (Output of the Junk) 
#    -> problem, R-Squared increases everytime an independant variable is added, which means the more independant variables the higher the R-Squared. 
# 2) Mean adjusted R-Squared = 0.54 (Output of the Junk) 
#    -> as soon as we take the problem with R-Squared into account and use the adjusted mean, we see that the value drops from 78% to 54% and that there are even negative single values. 
 
``` 
#### 1.2 Model Fit Variance Inflation Factors - (VIF’s) 
When your model includes continuous style factor variables the function ffmRsq also allows you to compute and display the time series of variance inflation factors (VIF’s). These can help you determine whether or not there are any regression collinearity problems.
 
```{r} 

# the time series of mean variance inflation factors (VIF’s) 
vif(fitDjia5Yr, 
    isPlot = T, 
    isPrint = F, 
    lwd = 0.7, 
    stripText.cex = 0.8, 
    axis.cex = 0.8) 
 
# Interpretation: 
# A value of 1 means not correlation with other variables:
# 1) The higher the value, the greater the correlation of the variable with other variables. 
# 2) The lower the value, the worse the correlation of the variable with other variables. 

# SIZE = 1.14 --> higher than 1 (more correlation) but not very big
# P2B = 1.09, --> higher than 1 (more correlation) but not very big
# EV2S = 1.15 --> higher than 1 (more correlation) but not very big

``` 
#### 1.3 Model Fit t-Statistics
Plots of the time series of t-statistics for the factors in an FFM fitted model, with horizontal dashed lines provided to judge whether or not a factor is significant at the 5% level, may be obtained with the function ffmTstats.
 
```{r} 

# The time series of t-statistics for the factors (5% significant level)
fmTstats(fitDjia5Yr, 
         whichPlot = "tStats", 
         color = "blue", 
         lwd = 0.7, 
         layout = c(3, 4), 
         stripText.cex = 0.8, 
         axis.cex = 0.8) 

# Interpretation:


``` 
 
```{r} 
# fmTstats can also compute the number of significant t-statistics:
#         the number of positive, 
#         negative and 
#         total significant t-statistics 

fmTstats(fitDjia5Yr, 
         whichPlot = "significantTstatsV", 
         color = "blue", 
         stripText.cex = 0.8, 
         axis.cex = 0.8, 
         layout = c(3, 4)) 

# Interpretation: 

``` 
 
### 2. Risk and Performance Report 
 The factorAnalytics package contains the following risk and performance reporting functions:
 1) repExposures
 2) repReturn
 3) repRisk 
 
We illustrate the use of each of these in turn using "fitDjia5Yr" and the corresponding global minimum variance long-only portfolio weights object "wtsDjiaGmvLo" 
 
```{r} 

# load the long-only global minimum variance portfolio weights vector 
data(wtsDjiaGmvLo) 

# and give it the shorter name wtsDjia 
wtsDjia = wtsDjiaGmvLo 

``` 
 
 
#### 2.1) repExposure 
The portfolio exposure to a given risk factor is the inner (dot) product of the portfolio weight vector with the column of the exposures matrix Bt−1 corresponding to the given factor. The style factors vary over time, but the sector factors are fixed and each sector is represented by a column of zero’s and ones. Thus the portfolio exposure to style factors will vary over time and thus have a distribution with a mean and volatility. On the other hand the portfolio exposure to sector factors will have a fixed value depending on the portfolio weights and number of firms in a given sector.
 
```{r} 

# compute volatilities of the style factors and sector factors 
repExposures(fitDjia5Yr,
             wtsDjia,
             isPlot = F,
             digits = 1, 
             stripText.cex = 0.8,
             axis.cex = 0.8) 

# Interpretation:
# Exposure generally refers to the fact of being exposed to a risk.
# Just three factors have a volatility:
# 1) Style factor P2B: with 20.0. 
# 2) Style factor EV2S: with 6.8
# 3) Stlye factor Size: with 4.6

``` 
 
 
 
```{r} 

# plot the volatilities of the style factors and sector factors 
repExposures(fitDjia5Yr, 
             wtsDjia, 
             isPrint = F, 
             isPlot = T, 
             which = 3, 
             add.grid = F, 
             zeroLine = T, 
             color = "Blue") 
``` 
 
 
```{r} 

# plot the time series of the style factor exposures 
repExposures(fitDjia5Yr, 
             wtsDjia, 
             isPrint = F, 
             isPlot = T, 
             which = 1, 
             add.grid = F, 
             zeroLine = T, 
             color = "Blue", 
             stripText.cex = 0.8,
             axis.cex = 0.8) 

``` 
 
```{r} 

#display boxplots of those exposures 
repExposures(fitDjia5Yr,
             wtsDjia,
             isPrint = FALSE, 
             isPlot = TRUE,
             which = 2,
             notch = F,
             layout = c(3,3)) 

``` 
 
 
#### 2.2) repReturn 
The function repReteurn provides you with the following choices of graphical reports, the results of which will also be printed because of the default printing option isPrint = T:
1. Time Series plot of portfolio returns decomposition
2. Time Series plot of portfolio style factors returns
3. Time Series plot of portfolio sector returns
4. Boxplot of Portfolio Returns Components.

 
```{r} 
# caluclate mean and volatility of the various portfolio return components with the help of repReturn 
repReturn(fitDjia5Yr,
          wtsDjia,
          isPlot = FALSE,
          digits = 2) 

# Interpretation: 
``` 
 
```{r} 

# Plot portfolio returns decomposition 
repReturn(fitDjia5Yr,
          wtsDjia,
          isPrint = FALSE,
          isPlot = TRUE, 
          which = 1,
          add.grid = TRUE,
          scaleType = "same", 
          color = "Blue",
          stripText.cex = 0.8,
          axis.cex = 0.8) 

# Interpretation: 

``` 
 
```{r} 

# Plot portfolio styles factor return 
repReturn(fitDjia5Yr, 
          wtsDjia, 
          isPrint = FALSE,
          isPlot = TRUE, 
          which = 2,
          add.grid = TRUE,
          zeroLine = T,
          color = "Blue", 
          scaleType = "same",
          stripText.cex = 0.8,
          axis.cex = 0.8) 

# Interpretation: 

``` 
 
```{r} 

# Plot portfolio sectors return 
repReturn(fitDjia5Yr,
          wtsDjia,
          isPrint = FALSE,
          isPlot = TRUE, 
          which = 3,
          add.grid = TRUE,
          zeroLine = T,
          color = "Blue", 
          scaleType = "same",
          stripText.cex = 0.8,
          axis.cex = 0.8) 

# Interpretation: 

``` 
 
```{r} 

# Boxplot of Portfolio Returns Components 
repReturn(fitDjia5Yr,
          wtsDjia,
          isPrint = FALSE,
          isPlot = TRUE,
          which = 4) 

# Interpretation: 

``` 

 
 
#### 2.3) repRisk 
The function *repRisk* allows one to compute and display (graphically and in tabular form) factor decompositions of risk for a portfolio and for each of the assets used to fit a fundamental factor model with fitFfm. The risk measure can be chosen as:
- standard deviation/volatility (SD)
- expected shortfall (ES)
- or value-at-risk (VaR)

and the factor risk decomposition can be chosen as:
- factor percent contribution to risk (FPCR)
- factor contribution to risk (FCR) 
- or factor marginal contribution to risk (FMCR). 
 
 
```{r} 
# standard deviation/volatility (SD)
# factor percent contribution to risk - (FPCR)

# First we compute an FPCR decomposition of the portfolio and individual assets using Sd as the risk measure, and provide both Lattice visualization and tabular displays. For the Lattice display the argument sliceby = “factor” specifies that the panel conditioning is by risk factor and the choice layout = c(5,1) results in a single row with five panels. We used nrowPrint = 10 to shorten the printed output from one row for the portfolio factor risk decomposition and 22 rows (we are only using 22 of the DJIA stocks at the moment) for the stock factor risk decompositions to one row for the portfolio and 9 rows for the assets. 
 
fitDjia5YrIntStyle = fitFfm(data = dataDjia5Yr,
                            exposure.vars = c("SIZE", "P2B", "EV2S"), 
                            date.var = "DATE", 
                            ret.var = "RETURN", 
                            asset.var = "TICKER", 
                            fit.method = "WLS", 
                            z.score = "crossSection", 
                            addIntercept = T) 
 
repRisk(fitDjia5YrIntStyle, 
        wtsDjia, 
        risk = "Sd", 
        decomp = "FPCR", 
        nrowPrint = 10, 
        sliceby = "factor", 
        isPrint = T, 
        isPlot = T, 
        layout = c(5, 1), 
        stripText.cex = 0.8, 
        axis.cex = 0.8) 

# Interpretation: 


``` 
 
```{r} 
# expected shortfall (ES)
# factor percent contribution to risk - (FPCR)

# Now we use expected shortfall (ES) to do an FPCR decomposition and provide only the Lattice 
repRisk(fitDjia5YrIntStyle, 
        wtsDjia, 
        risk = "ES", 
        decomp = "FPCR", 
        nrowPrint = 10, 
        sliceby = "factor", 
        isPrint = F, 
        isPlot = T, 
        layout = c(5, 1),
        stripText.cex = 0.8, 
        axis.cex = 0.8) 

# Interpretation: 

``` 
 
```{r} 

# expected shortfall (ES)
# factor contribution to risk (FCR) 

# Now we use expected shortfall (ES) to do the FCR decomposition 

repRisk(fitDjia5YrIntStyle, 
        wtsDjia, 
        risk = "ES",
        decomp = "FCR", 
        nrowPrint = 10,
        sliceby = "factor",
        isPrint = F, 
        isPlot = T,
        layout = c(5, 1),
        stripText.cex = 0.8, 
        axis.cex = 0.8) 

# Interpretation: 

``` 
 
```{r} 

# compare the factor risk decompositions of a portfolio using all three risk measures, skipping the risk decomposition of the assets 
repRisk(fitDjia5YrIntStyle, 
        wtsDjia, 
        risk = c("Sd", "ES", "VaR"),
        decomp = "FPCR",
        sliceby = "factor", 
        isPrint = T,
        isPlot = TRUE,
        layout = c(5, 1),
        portfolio.only = T, 
        stripText.cex = 0.8,
        axis.cex = 0.8) 

# Interpretation: 

``` 
 
### 3. Factor Model Monte Carlo 
The use of factor model Monte Carlo (FMMC) for a fundamental factor model results in a simulated set of asset returns based on a resampling of factor returns and a resampling or simulation of residual returns of the fitted model, using the exposures matrix from the last time period used in fitting the model.  
The factorAnalytics function fmmcSemiParametric implements the above FMMC method based on function araguments that are the result of first fitting  fundamental factor model to the data with fitFfm, combined with function arguments based on user options concerning the type of FMMC. We will illustrate the use of fmmcSemiParametric on the DJIA five-year monthly data set factorDataSetDjia5Yrs. 

 
```{r} 

# But first we take a look at the arguments of the function 
args(fmmcSemiParam) 

``` 
Aguments:
- B is the number of bootstrap samples.
- factor.ret is the set of factor returns estimates returned by the use of fitFfm
- beta is exposures matrix for the final period returned by fitFfm
- alpha is a fixed vector of intercept values that if ommited are assumed to be zero. 

Our example below uses the default values B = 1000, boot.method = “random” (means simple bootstrap), seed = 123 (for reproducibility of the example).  

We use two choices of resid.dist, first we use resid.dist = “empirical” which corresponds to 2-(a) above and then we use resid.dist = “normal”. The user must provide appropriate values for resid.par that depend on the the choice for resid.dist. For the choice resid.dist = “empirical” the resid.par must be the N × T dimensional xts time series in the $residuals component of the model fit, and for the choice resid.dist = “normal” the resid.par must be an N × 2 matrix with the first column being estimates of the means of the residuals for each of the N assets and the second column being estimates of the standard deviations of the residuals for each of the assets 
 
```{r} 
# In order to use fmmcSemiParam for the DJIA data we first fit a fundamental factor model (without alpha or market term) to the factorDataSetDjia5Yrs data 
data("factorDataSetDjia5Yrs") 
N = 30 

exposure.vars <- c("P2B", "MKTCAP", "SECTOR") 

fit.ffm = fitFfm(data = factorDataSetDjia5Yrs,
                 asset.var = "TICKER", 
                 ret.var = "RETURN",
                 date.var = "DATE",
                 exposure.vars = exposure.vars) 
``` 
 
```{r} 

# Next we use fmmcSemiParam to create simulated values of the asset returns based on the use of bootstrapped factor returns and bootstrapped (empirical) residuals: 
resid.par = fit.ffm$residuals 

fmmcDat = fmmcSemiParam(B = 1000,
                        factor.ret = fit.ffm$factor.returns, 
                        beta = fit.ffm$beta, 
                        resid.par = resid.par,
                        boot.method = "random", 
                        resid.dist = "empirical") 
names(fmmcDat) 
``` 
"sim.fund.ret" = a B × N matrix of simulated asset returns, "boot.factor.ret" = a B × K matrix of simulated factor returns, "sim.resid" = a B × N matrix of simulated residuals 
 
```{r} 

# Now let’s verify that the that returns of the 30 DJIA stocks over the five-year period are well represented by the set of 500 simulated sets of 30 returns in fmmcDat$sim.fund.return with respect to returns means and standard deviations. In order to do this we first extract the multivariate time series of returns of those stocks from the data frame factorDataSetDjia5Yrs 
data = factorDataSetDjia5Yrs 

djiaDat = tapply(data$RETURN,
                 list(data$DATE, data$TICKER),
                 I) 

djiaRet = xts(djiaDat,
              as.yearmon(rownames(djiaDat))) 

``` 
 
```{r} 

# Now we compare the simulated returns means with the observed returns means for the first 10 DJIA stocks 
round(apply(djiaRet, 2, mean)[1:10], 3) 

round(apply(fmmcDat$sim.fund.ret, 2, mean)[1:10], 3) 

``` 
 
```{r} 

#same thing for returns standard deviations 
round(apply(djiaRet, 2, sd)[1:10], 3) 
round(apply(fmmcDat$sim.fund.ret, 2, sd)[1:10], 3) 

``` 
 
The use of *fmmcSemiParam* with bootstrapped residuals as well as bootstrapped factor returns is attractive because it is simple and because in addition to making no distributional assumptions about the factor returns it makes no assumptions about the distributions of the residuals. 
 
By way of contrast let’s see what happens if we assume the residuals associated with the 30 DJIA fitted fundamental factor model returns have normal distributions and fit them using the sample means and standard deviations of the residuals.  
 
 
```{r} 

# First we use fmmcSemiParam with default choice resid.dist = “normal” and with resid.par a matrix with first column the sample mean of the residuals and second column the standard deviation of teh residuals 
 
resid.mean = apply(B = 1000,
                   coredata(fit.ffm$residuals),
                   2, 
                   mean,
                   na.rm = T) 

resid.sd = matrix(sqrt(fit.ffm$resid.var)) 
 
resid.par = cbind(resid.mean, resid.sd) 

fmmcDatNormal = fmmcSemiParam(factor.ret = fit.ffm$factor.returns, 
                             beta = fit.ffm$beta, 
                             resid.par = resid.par,
                             boot.method = "random") 
``` 
 
```{r} 

#Then we compare the means of the simulated asset returns with those of the actual returns 
round(apply(djiaRet, 2, mean)[1:10], 3) 
round(apply(fmmcDatNormal$sim.fund.ret, 2, mean)[1:10], 3) 

``` 
 
```{r} 

#Same with the standard deviation 
round(apply(djiaRet, 2, sd)[1:10], 3) 
round(apply(fmmcDatNormal$sim.fund.ret, 2, sd)[1:10], 3)

``` 
 
Once again the mean values agree quite well, but we see that the simulated returns based on the assumption of normally distributed returns have volatilities that under-estimate the actual returns volatilities for eight of the first 10 stocks. However, comparison of the volatilities for all 30 stocks reveals that there are only 13 stocks for which the volatilites for the simulated returns are smaller than those of the actual returns, and that when the volatilities of the simulated returns are larger than those of the actual returns they are much larger, for example .093 versus .065 for CAT and .132 versu .068 for HD 
 
Main message: It is not safe to use normal distributions in modeling stock returns with a fundamental factor model (or otherwise). It is for this reason that fmmcSemiParam allows you to use skewed t-distributions and Cornish-Fisher quantile rerpresentation of non-normal distributions for the residuals. 
 
 
### 4. Market plus Industry plus Country Model 
 
In this discussion we treat the terms “Industry” and “Sector” interchangeably, noting that for some models, e.g., a U.S. equity model, one may prefer to just use sector factors but may also wish to use industry factors, and a global model with countries may also contain industry factors. Our current examples use sector factors but we refer to them in our mathematical models loosely as industry factors. 
 
 
We will illustrate use of fitFfm to fit a market plus sector model to the DJIA stock returns and sector data. But first we fit a pure sector model without a market component and examine the factor return coefficients for the first month of the five-year fitting window as a reference point. 
 
```{r} 

dat = factorDataSetDjia5Yrs 
fitSec = fitFfm(dat,
                asset.var = "TICKER",
                ret.var = "RETURN", 
                date.var = "DATE",
                exposure.vars = "SECTOR") 

``` 

```{r} 

round(coef(summary(fitSec)$sum.list[[1]])[, 1], 3) 
round(fitSec$factor.returns[1, ], 3) 

``` 
 
Note that the last two lines of code produce identical results. This is because without any constraints such as those discussed above, the coefficients of the cross-section regression at each time period are extracted to form the time series of factor returns in the factor.returns component of the ffm object. Now we fit a market plus sector model by adding the fitF argument addIntercept = T,and examine the coefficients gˆmi,1 and the resulting factor returns ˆfmi,1 for the first month of the fiveyear fitting window. 
 
```{r} 

fitSecInt = fitFfm(dat,
                   asset.var = "TICKER",
                   ret.var = "RETURN", 
                   date.var = "DATE",
                   exposure.vars = "SECTOR",
                   addIntercept = T) 

round(coef(summary(fitSecInt)$sum.list[[1]])[, 1], 2) 

``` 

```{r} 

round(fitSecInt$factor.returns[1, ], 2) 

``` 
 
```{r} 

round(sum(fitSecInt$factor.returns[1, -1]), 2) 

``` 
 
Note that the next to last line of code above prints the unique least squares model coefficients vector gˆmi,1 for month 1 (9 of them since there are 9 sectors) 
 
 
### 5. A Simultated Data Example 
 
We have created an artificial example of a market+sector+country model (where sector plays the role of industry) consisting of *random returns* of 30 stocks with three sectors for the sector factor and two countries for the countries factor, for each of five months. The *normally distributed returns* for the three sectors alone have means of 1, 2, 3, with standard deviations .2. The two countries contribute additional *normally distributed* returns having means 4 and 5 with standard deviations .2. So returns associated with the first country have means 5, 6, 7 and means associated with the second country have means 6, 7, 8. Thus the overall mean of 6.5. The code for creating the returns is as follows: 
 
```{r} 

# Country Incremental Components of Asset Returns 

set.seed(10000)

Bind = cbind(rep(1, 30), 
             c(rep(1, 10), rep(0, 20)), 
             c(rep(0, 10), rep(1, 10), rep(0, 10)), 
             c(rep(0, 20), rep(1, 10))) 

cty1 = matrix(rep(c(0, 1), 15)) 

cty2 = matrix(rep(c(1, 0), 15)) 

Bmic = cbind(Bind, cty1, cty2) 

dimnames(Bmic)[[2]] = c("mkt", "sec1", "sec2", "sec3", "cty1", "cty2") 

r.add = rnorm(30, 4, 0.2) 
r.cty1 = rep(0, 30) 
r.cty2 = rep(0, 30) 

for (i in 1:30) 
  {
  if (Bmic[i, "cty1"] == 1) 
    { 
    r.cty1[i] = r.add[i] 
    r.cty2[i] = 0 
    } 
  else 
    { 
      r.cty1[i] = 0
      r.cty2[i] = r.add[i] + 1
    } 
  } 


# Asset Returns for Market+Industry+Country Model 
mu = c(1, 2, 3) 
sd = c(0.2, 0.2, 0.2) 
r = list() 
r.mic = list() 
fitMic = list() 
fitMic1 = list() 

for (i in 1:5) 
  {
  set.seed(1099923 + (i - 1)) 
  r[[i]] = c(rnorm(10, mu[1], sd[1]), 
             rnorm(10, mu[2], sd[2]), 
             rnorm(10, mu[3], sd[3])) 
  r.mic[[i]] = r[[i]] + r.cty1 + r.cty2 
  } 

``` 
 
```{r} 

#qq-plot of the 30 asset returns for the first of the 5 time periods 
qqnorm(r.mic[[1]],
       main = "MIC Model Equity Returns for First Period", 
       xlab = "NORMAL QQ-PLOT",
       ylab = "RETURNS") 
 

# Print out of 30 asset returns for the first time period!
r.mic[[1]] 

# Interpretation: 
# QQ Plot Theorie:
# The observed values of a characteristic are ordered by size. The quantiles of the theoretical distribution, which belong to the corresponding distribution value, serve as comparison. If the *characteristic values* originate from the *comparison distribution*, the empirical and the theoretical quantiles approximately agree = the values lie on a diagonal. Large systematic deviations from this diagonal indicate that the theoretical and empirical distribution differ from each other. However, the quantile-quantile diagram cannot replace a distribution test.

# --> our results approximately lie on a diagonal. Small deviations between the distributions!



``` 
 
Now we build the data frame required by fitFfm, fit the *MIC (Market-Industry-country) model* and display the factor returns for each of the five months. What we have been calling the Industry factor is called Sector for this example 
 
```{r} 
# Build the data frame 
# Extracts a the return element from the list of lists
Returns = unlist(r.mic) 

# Build the country listing
COUNTRY = rep(rep(c("US", "India"), 15), 5) 

# Build the sector listing
SECTOR = rep(rep(c("SEC1", "SEC2", "SEC3"), each = 10), 5) 

# Build the ticker listing (don't know for what purpose?)
TICKER = rep(c(LETTERS[1:26], paste0("A", LETTERS[1:4])), 5) 

# Build the date listing with 5 time periods for 30 stocks
DATE = rep(seq(as.Date("2000/1/1"), by = "month", length.out = 5), each = 30) 

# fill up the data frame
data.mic = data.frame(DATE = as.character(DATE),
                      TICKER, 
                      Returns, 
                      SECTOR, 
                      COUNTRY) 


exposure.vars = c("SECTOR", "COUNTRY") 


# Fit a fundamental (cross-sectional) factor model using ordinary least squares or robust regression. Fundamental factor models use observable asset specific characteristics (or) fundamentals, like industry classification, market capitalization, style classification (value, growth) etc. to calculate the common risk factors.
fit = fitFfm(data = data.mic,
             asset.var = "TICKER", 
             ret.var = "Returns",
             date.var = "DATE",
             exposure.vars = exposure.vars, 
             addIntercept = T) 


# Returns of the FFM of the 5 time periods for the market, the three sectors/industries and the 2 countries. 
fit$factor.returns 

# Interpretation: 
# We see the return attributable to a particular common factor (market). We decompose asset returns into common factor components, based on the asset's exposures to common factors times the factor returns, and a specific return. 
# Specific interpretation:
# We see that the Market values of the factor have values clustering around 6.5 as expected. 
# We can also see that the three sector factor returns sum to zero and the two country factor returns sum to zero, as expected due to the constraints that they sum to zero. (deviations from the market return)


fit$factor.fit
# unique least squares model coefficients vector

# covariance if wanted
# fit$g.cov
# fit$resid.cov
#fit$return.cov	
``` 
